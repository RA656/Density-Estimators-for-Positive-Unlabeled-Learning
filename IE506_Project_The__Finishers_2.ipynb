{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# For Random Forest Classifier"
      ],
      "metadata": {
        "id": "MhbeEtf2ey4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcF3L1ToBYqm",
        "outputId": "0917ce36-3c00-4f05-fad6-f2e447d5f46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4NofiIUALP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fecc5b8-4cd4-452f-d7af-46c2e76d2130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=17d178fc6c23a7240442b2029850336c76fcae8965d2b0869a1dd718766d84b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/82/8b/5c514221984e88c059b94e36a71d4722e590acaae04deab22e\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "!pip install liac-arff\n",
        "import arff\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/CODE/GPU-master.zip"
      ],
      "metadata": {
        "id": "a2WTjX-JFx8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73e6936-aad1-4de8-a354-8f41542675aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/CODE/GPU-master.zip\n",
            "  inflating: GPU-master/bn_k2.R      \n",
            "   creating: GPU-master/data/\n",
            "  inflating: GPU-master/data/audiology.tar.gz  \n",
            "  inflating: GPU-master/data/breast-cancer.tar.gz  \n",
            "  inflating: GPU-master/data/chess.tar.gz  \n",
            "  inflating: GPU-master/data/dermatology.tar.gz  \n",
            "  inflating: GPU-master/data/hepatitis.tar.gz  \n",
            "  inflating: GPU-master/data/lymph.tar.gz  \n",
            "  inflating: GPU-master/data/nursery.tar.gz  \n",
            "  inflating: GPU-master/data/pima.tar.gz  \n",
            "  inflating: GPU-master/data/soybean.tar.gz  \n",
            "  inflating: GPU-master/data/vote.tar.gz  \n",
            "  inflating: GPU-master/gpu.py       \n",
            "  inflating: GPU-master/LICENSE      \n",
            "  inflating: GPU-master/README.md    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpsr6br0pkpg",
        "outputId": "3e8937e2-8dc9-450c-a91a-04caf31f7525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd GPU-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKW8BvulpoN7",
        "outputId": "91726ec1-c110-4168-fa0a-2c572d051b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPU-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['audiology','breast-cancer', 'chess', 'hepatitis', 'nursery', 'soybean', 'vote']"
      ],
      "metadata": {
        "id": "PHAMPaPjGEGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "for i in datasets:\n",
        "  file = tarfile.open('data/' + i + '.tar.gz')\n",
        "  file.extractall('data/')\n",
        "  file.close()"
      ],
      "metadata": {
        "id": "iMqcBNLCp2f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv(filename):\n",
        "    file = open(filename, \"r\")\n",
        "    lines = csv.reader(file)\n",
        "    dataset = list(lines)\n",
        "    return np.array(dataset)"
      ],
      "metadata": {
        "id": "OWDuYsjWF5Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv(data, path):\n",
        "    with open(path, \"w\") as csv_file:\n",
        "        writer_ = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
        "        for line in data:\n",
        "            writer_.writerow(line)"
      ],
      "metadata": {
        "id": "80rPCVcZF8tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_int(value):\n",
        "     try:\n",
        "         int(value)\n",
        "         return True\n",
        "     except ValueError:\n",
        "         return False"
      ],
      "metadata": {
        "id": "_S8ugadNF_p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['cochlear_age','no-recurrence-events', 'won', 'DIE',  'not_recom',  'brown-spot', 'democrat']"
      ],
      "metadata": {
        "id": "gq2qP70wGPb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-NHUhmfp16L",
        "outputId": "29046992-ad3a-46cc-e7bf-1ee7feb7e6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_class_labels = ['cochlear_unknown', 'recurrence-events', 'nowin', 'LIVE',  'priority',  'alternarialeaf-spot', 'republican']"
      ],
      "metadata": {
        "id": "gbwUNAF_GXyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(neg_class_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YWUweoWp_YH",
        "outputId": "f26f4c76-7e84-49ad-e254-6b6a46ab3017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('results', 'w') as output:\n",
        "    output.write('Dataset,perc,pos,ones,precision,recall,f1-score\\n')\n",
        "\n",
        "    for dataset, class_label, neg_class_label in zip(datasets,class_labels, neg_class_labels):\n",
        "        #creating feature filename for bnlearn\n",
        "        data_filename = 'data/' + dataset + '_train_pos_50_1.arff'\n",
        "        data = arff.load(open(data_filename, 'r'))\n",
        "        features_name = 'data/' + dataset + '.features'\n",
        "        log_file = 'data/' + dataset + '.log'\n",
        "\n",
        "        out_log_file = open(log_file,\"w\")\n",
        "        out_log_file.write('perc,fold,ones,n_estimators,precision,recall,f1-score\\n')\n",
        "        out_log_file.flush()\n",
        "\n",
        "        with open(features_name, 'w') as features_file:\n",
        "            for attr in data['attributes'][:-1]:\n",
        "                features_file.write('\"' + attr[0] + '\":categorical:')\n",
        "                for val in attr[1][:-1]:\n",
        "                    features_file.write('\"' + val + '\",')\n",
        "                if attr[1][-1] != '':\n",
        "                    features_file.write('\"' + attr[1][-1] + '\".\\n')\n",
        "                else:\n",
        "                    features_file.write('\".\\n')\n",
        "\n",
        "\n",
        "        for perc in ['30', '40', '50']:\n",
        "\n",
        "            precision_f =  []\n",
        "            recall_f = []\n",
        "            f1_score_f = []\n",
        "            ones_f = []\n",
        "\n",
        "            for fold in range(1,11):\n",
        "                print('Fold:', fold)\n",
        "\n",
        "                pos_name = 'data/' + dataset + '_train_pos_' + perc + '_' + str(fold) + '.arff'\n",
        "                unl_name = 'data/' + dataset + '_train_unl_' + perc + '_' + str(fold) + '.arff'\n",
        "                test_name = 'data/' + dataset + '_test_' + perc + '_' + str(fold) + '.arff'\n",
        "\n",
        "\n",
        "                train_pos = arff.load(open(pos_name, 'r'))\n",
        "                train_unl = arff.load(open(unl_name, 'r'))\n",
        "                test = arff.load(open(test_name, 'r'))\n",
        "\n",
        "                train_pos_data = np.array(train_pos['data'])\n",
        "                train_unl_data = np.array(train_unl['data'])\n",
        "\n",
        "                test_data = np.array(test['data'])\n",
        "\n",
        "                write_csv(train_pos_data[:,:-1],'./data/pos.data')\n",
        "                write_csv(train_unl_data[:,:-1],'./data/unl.data')\n",
        "\n",
        "\n",
        "                command = 'R --no-save --args ./data/' + dataset + '.features ./data/pos ./data/unl outfile < bn_k2.R > /dev/null'\n",
        "\n",
        "                os.system(command)\n",
        "\n",
        "                lls = np.loadtxt('outfile')\n",
        "\n",
        "                argsort = np.argsort(lls)\n",
        "\n",
        "                ones = 0\n",
        "                for index in argsort[:train_pos_data.shape[0]]:\n",
        "                    if train_unl_data[index,-1]==class_label:\n",
        "                        ones = ones + 1\n",
        "\n",
        "\n",
        "                X_train_pos_neg = np.concatenate((train_pos_data[:,:-1], train_unl_data[argsort[:train_pos_data.shape[0]],:-1]), axis=0)\n",
        "                y_train_pos_neg = np.array([class_label]*train_pos_data.shape[0] + [neg_class_label]*train_pos_data.shape[0])\n",
        "\n",
        "                X_train_pos_neg_int = np.zeros((X_train_pos_neg.shape[0],X_train_pos_neg.shape[1]))\n",
        "                attributes = train_pos['attributes']\n",
        "                for i in range(X_train_pos_neg.shape[1]):\n",
        "                    values = attributes[i][1]\n",
        "                    for j in range(X_train_pos_neg.shape[0]):\n",
        "                        X_train_pos_neg_int[j,i] = values.index(X_train_pos_neg[j,i])\n",
        "\n",
        "                X_test_int = np.zeros((test_data.shape[0],test_data.shape[1]-1))\n",
        "                attributes = train_pos['attributes']\n",
        "                for i in range(test_data.shape[1]-1):\n",
        "                    values = attributes[i][1]\n",
        "                    for j in range(test_data.shape[0]):\n",
        "                        X_test_int[j,i] = values.index(test_data[j,i])\n",
        "\n",
        "                X_all_int = np.concatenate((X_train_pos_neg_int, X_test_int), axis=0)\n",
        "\n",
        "                encoder = OneHotEncoder()\n",
        "                encoder.fit(X_all_int)\n",
        "                A = encoder.transform(X_train_pos_neg_int).toarray()\n",
        "                B = encoder.transform(X_test_int).toarray()\n",
        "\n",
        "                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=177)\n",
        "                #cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=177)\n",
        "                f1_scorer = make_scorer(f1_score, pos_label=neg_class_label)\n",
        "\n",
        "\n",
        "                rf_params = {'n_estimators': [10,50,100,200]}\n",
        "                rf = RandomForestClassifier()\n",
        "                grid = GridSearchCV(rf, rf_params, cv = cv, scoring = f1_scorer , n_jobs=-1)\n",
        "                grid.fit(A, y_train_pos_neg)\n",
        "\n",
        "                print(\"The best parameters are %s with a score of %0.2f\"\n",
        "                       % (grid.best_params_, grid.best_score_))\n",
        "                n_estimators = grid.best_params_['n_estimators']\n",
        "\n",
        "                clf = RandomForestClassifier(n_estimators = n_estimators)\n",
        "                clf.fit(A, y_train_pos_neg)\n",
        "                y_train_pred = clf.predict(A)\n",
        "\n",
        "\n",
        "                print('Train stats')\n",
        "                pr = metrics.precision_score(y_train_pos_neg,y_train_pred, average='macro')\n",
        "                re = metrics.recall_score(y_train_pos_neg,y_train_pred, average='macro')\n",
        "                f1 = metrics.f1_score(y_train_pos_neg,y_train_pred, average='macro')\n",
        "                print('Precision:', pr)\n",
        "                print('Recall:', re)\n",
        "                print('F1-score:', f1)\n",
        "\n",
        "                y_test_pred = clf.predict(B)\n",
        "\n",
        "                print('Test stats')\n",
        "                pr = metrics.precision_score(test_data[:,-1],y_test_pred, average='macro')\n",
        "                re = metrics.recall_score(test_data[:,-1],y_test_pred, average='macro')\n",
        "                f1 = metrics.f1_score(test_data[:,-1],y_test_pred, average='macro')\n",
        "                print('Precision:', pr)\n",
        "                print('Recall:', re)\n",
        "                print('F1-score:', f1)\n",
        "\n",
        "                precision_f.append(pr)\n",
        "                recall_f.append(re)\n",
        "                f1_score_f.append(f1)\n",
        "                ones_f.append(ones)\n",
        "\n",
        "                out_log_file.write(str(perc) + ',' + str(fold) + ',' +str(ones) + ',' +str(n_estimators) + ',' + str(pr) + ',' + str(re) + ',' + str(f1) +'\\n')\n",
        "                out_log_file.flush()\n",
        "\n",
        "            output.write(dataset + ',' + perc + ',')\n",
        "            output.write(str(train_pos_data.shape[0]) + ',' +\n",
        "                         str(np.mean(ones_f)) + ',' +\n",
        "                         str(np.mean(precision_f)) + ',' +\n",
        "                         str(np.mean(recall_f)) + ',' +\n",
        "                         str(np.mean(f1_score_f)) + '\\n')\n",
        "\n",
        "            output.flush()\n",
        "        out_log_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w40kPOLShUOa",
        "outputId": "005636e2-20c7-4a83-a19e-720b3f157841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 1\n",
            "The best parameters are {'n_estimators': 100} with a score of 0.96\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 0.9285714285714286\n",
            "Recall: 0.9\n",
            "F1-score: 0.905982905982906\n",
            "Fold: 2\n",
            "The best parameters are {'n_estimators': 10} with a score of 0.92\n",
            "Train stats\n",
            "Precision: 0.9705882352941176\n",
            "Recall: 0.96875\n",
            "F1-score: 0.9687194525904204\n",
            "Test stats\n",
            "Precision: 0.8571428571428572\n",
            "Recall: 0.8\n",
            "F1-score: 0.7916666666666665\n",
            "Fold: 3\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.90\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 4\n",
            "The best parameters are {'n_estimators': 100} with a score of 0.91\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 0.9166666666666667\n",
            "Recall: 0.9\n",
            "F1-score: 0.898989898989899\n",
            "Fold: 5\n",
            "The best parameters are {'n_estimators': 10} with a score of 0.92\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 6\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.93\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 7\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.93\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 8\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.90\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 9\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.97\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 10\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.90\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 1\n",
            "The best parameters are {'n_estimators': 50} with a score of 1.00\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 2\n",
            "The best parameters are {'n_estimators': 10} with a score of 0.94\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 0.8\n",
            "Recall: 0.8\n",
            "F1-score: 0.8000000000000002\n",
            "Fold: 3\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.89\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 4\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.89\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 5\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.94\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 0.9166666666666667\n",
            "Recall: 0.9166666666666667\n",
            "F1-score: 0.9090909090909091\n",
            "Fold: 6\n",
            "The best parameters are {'n_estimators': 50} with a score of 0.97\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 7\n",
            "The best parameters are {'n_estimators': 100} with a score of 0.98\n",
            "Train stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Test stats\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Fold: 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-db6bf1a4480a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_scorer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pos_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 print(\"The best parameters are %s with a score of %0.2f\"\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-rb-JnPj7YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}